{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b52cf84-5d03-47f9-8d16-06a02ee93a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (token_embed): Embedding(50257, 256)\n",
       "  (pos_embed): Embedding(128, 256)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (ln1): LayerNorm()\n",
       "      (ln2): LayerNorm()\n",
       "      (att): MultiHeadAttention(\n",
       "        (q): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (k): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (v): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (ln1): LayerNorm()\n",
       "      (ln2): LayerNorm()\n",
       "      (att): MultiHeadAttention(\n",
       "        (q): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (k): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (v): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (ln1): LayerNorm()\n",
       "      (ln2): LayerNorm()\n",
       "      (att): MultiHeadAttention(\n",
       "        (q): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (k): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (v): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (ln1): LayerNorm()\n",
       "      (ln2): LayerNorm()\n",
       "      (att): MultiHeadAttention(\n",
       "        (q): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (k): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (v): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (ln_f): LayerNorm()\n",
       "  (head): Linear(in_features=256, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-définis ta config si tu relances le notebook\n",
    "cfg = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"emb_dim\": 256,\n",
    "    \"context_length\": 128,\n",
    "    \"n_heads\": 4,\n",
    "    \"n_layers\": 4,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": True\n",
    "}\n",
    "\n",
    "# Recrée le modèle et charge les poids\n",
    "model = GPTModel(cfg)\n",
    "model.load_state_dict(torch.load(\"picogpt.pt\", map_location=device))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be552d4a-3046-42cc-a755-7683eba5facc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d249d743-347c-4bdb-8c3b-6eed53e0306a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, tokenizer, prompt, max_new_tokens=50, temperature=1.0, stop_token=\"<|endoftext|>\"):\n",
    "    model.eval()\n",
    "    tokens = tokenizer.encode(prompt)\n",
    "    x = torch.tensor(tokens, dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        x_cond = x[:, -cfg[\"context_length\"]:]  # Tronquer si trop long\n",
    "        with torch.no_grad():\n",
    "            logits = model(x_cond)\n",
    "            logits = logits[:, -1, :] / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            next_token = torch.multinomial(probs, num_samples=1)\n",
    "\n",
    "        x = torch.cat([x, next_token], dim=1)\n",
    "\n",
    "        if tokenizer.decode([next_token.item()]) == stop_token:\n",
    "            break\n",
    "\n",
    "    return tokenizer.decode(x[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b23b3c70-6a5a-4922-b6fb-5763157dc47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Output ===\n",
      "the cat reads quietly.\n",
      "the sun eats a song.\n",
      "my dog walks with me.\n",
      "my dog jumps a book.\n",
      "a bird walks a song.\n",
      "the sun jumps a song eats milk.\n",
      "my dog fast.\n",
      "my dog drinks in\n"
     ]
    }
   ],
   "source": [
    "prompt = \"the cat\"\n",
    "output = generate(model, tokenizer, prompt, max_new_tokens=50, temperature=0.8)\n",
    "print(\"=== Output ===\")\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
